# Notebooks de Databricks

### Índice

1. [Introducción a los Notebooks de Databricks](#introducción-a-los-notebooks-de-databricks)
2. [Creación y gestión de notebooks](#creación-y-gestión-de-notebooks)
3. [Ejecución de celdas y administración de variables](#ejecución-de-celdas-y-administración-de-variables)
4. [Visualización de resultados](#visualización-de-resultados)

---

## Introducción a los Notebooks de Databricks

Los Notebooks de Databricks son un entorno interactivo y colaborativo que te permite escribir y ejecutar código Scala en Spark de manera eficiente. En este manual, aprenderemos cómo aprovechar al máximo los Notebooks de Databricks para trabajar con Spark y Scala.

---

## Creación y gestión de notebooks

Para comenzar a utilizar los Notebooks de Databricks, sigue los siguientes pasos:

1. Inicia sesión en tu cuenta de Databricks.
2. En el panel de control, selecciona el proyecto o espacio de trabajo adecuado.
3. Haz clic en "Create" o "Create Notebook" para crear un nuevo notebook.
4. Asigna un nombre descriptivo al notebook y selecciona el lenguaje Scala.
5. A continuación, podrás acceder al notebook y comenzar a escribir código Scala en las celdas.

---

## Ejecución de celdas y administración de variables

Una vez que has creado un notebook, puedes trabajar con celdas individuales que contienen código Scala. Aquí hay algunas acciones clave que puedes realizar en las celdas:

- Para ejecutar una celda, selecciona la celda y presiona Shift + Enter. El código Scala se ejecutará y podrás ver la salida o el resultado si corresponde.
- Puedes ejecutar celdas en cualquier orden, lo que te permite iterar y probar diferentes secciones de código.
- Las variables creadas en una celda se mantienen en memoria y se pueden acceder desde otras celdas en el mismo notebook.
- Puedes reiniciar el kernel de Scala en cualquier momento para borrar todas las variables y reiniciar desde cero.

---

## Visualización de resultados

Databricks ofrece varias opciones para visualizar resultados y generar gráficos a partir de los datos. A continuación, se muestran algunas de las formas comunes de visualizar resultados en los Notebooks de Databricks:

- Puedes utilizar la función `display` para mostrar tablas y gráficos en formato interactivo.
- Databricks también es compatible con bibliotecas populares de visualización, como Matplotlib y ggplot, que se pueden utilizar para crear gráficos personalizados.
- Puedes exportar los resultados y gráficos generados en diferentes formatos, como PNG o CSV, para su posterior análisis o uso externo.

¡Explora y experimenta con las capacidades de visualización de Databricks para presentar tus resultados de manera efectiva!

---

Este fue el Manual 1 del dominio de Spark con Scala utilizando Databricks. En el siguiente manual, abordaremos los conceptos de transformaciones y acciones en Spark. ¡Sigue adelante con tu aprendizaje!